package neuralnetwork;

import java.util.*;

public class ConvolutionalLayer implements Spread {
    private int inputWidth;    // è¾“å…¥å›¾åƒçš„å®½åº¦
    private int inputHeight;   // è¾“å…¥å›¾åƒçš„é«˜åº¦
    private int inputDepth;    // è¾“å…¥å›¾åƒçš„æ·±åº¦(é€šé“æ•°)
    private int kernelSize;    // å·ç§¯æ ¸å°ºå¯¸(å‡è®¾ä¸ºæ­£æ–¹å½¢)
    private int neuronCount;    // ç¥ç»å…ƒ/æ»¤æ³¢å™¨æ•°é‡
    private static final int stride = 1;        // å·ç§¯æ­¥é•¿
    private static final int padding = 0;       // å¡«å……å¤§å°

    public double[][][][] kernels;  // å·ç§¯æ ¸ [neuronCount][depth][width][height]
    private double[] biases;        // æ¯ä¸ªç¥ç»å…ƒçš„åç½®

    private double[][][] lastInput; // ä¿å­˜ä¸Šä¸€æ¬¡çš„è¾“å…¥ç”¨äºåå‘ä¼ æ’­

    // æ·»åŠ æ¿€æ´»å€¼æ§åˆ¶å‚æ•°
    private static final double MAX_ACTIVATION = 6.0; // é™åˆ¶å•ä¸ªæ¿€æ´»å€¼

    /**
     * æ„é€ å‡½æ•°
     * @param inputWidth è¾“å…¥å®½åº¦
     * @param inputHeight è¾“å…¥é«˜åº¦
     * @param inputDepth è¾“å…¥æ·±åº¦(é€šé“æ•°)
     * @param kernelSize å·ç§¯æ ¸å°ºå¯¸
     * @param neuronCount æ»¤æ³¢å™¨æ•°é‡
     */
    public ConvolutionalLayer(int inputDepth, int inputWidth, int inputHeight,
                            int kernelSize, int neuronCount) {
        this.inputWidth = inputWidth;
        this.inputHeight = inputHeight;
        this.inputDepth = inputDepth;
        this.kernelSize = kernelSize;
        this.neuronCount = neuronCount;

    }

    public void initParams() {
        Random rand = new Random();

        // ä½¿ç”¨ He åˆå§‹åŒ–ï¼ˆé€‚åˆ ReLU æ¿€æ´»å‡½æ•°ï¼‰
        double stddev = Math.sqrt(2.0 / (kernelSize * kernelSize * inputDepth));

        kernels = new double[neuronCount][inputDepth][kernelSize][kernelSize];
        for (int f = 0; f < neuronCount; f++) {
            for (int d = 0; d < inputDepth; d++) {
                for (int i = 0; i < kernelSize; i++) {
                    for (int j = 0; j < kernelSize; j++) {
                        kernels[f][d][i][j] = rand.nextGaussian() * stddev;
                    }
                }
            }
        }

        biases = new double[neuronCount];
        for (int f = 0; f < neuronCount; f++) {
            biases[f] = 0.0; // æˆ–è€… 0.1 * rand.nextGaussian()
        }
    }

    /**
     * å‰å‘ä¼ æ’­
     * @param input è¾“å…¥æ•°æ® [depth][width][height]
     * @return å·ç§¯åçš„ç‰¹å¾å›¾ [filter][width][height]
     */
    @Override
    public double[][][] forward(double[][][] input) {
        this.lastInput = input; // ä¿å­˜è¾“å…¥ç”¨äºåå‘ä¼ æ’­

        int outputWidth = (inputWidth - kernelSize + 2 * padding) / stride + 1;
        int outputHeight = (inputHeight - kernelSize + 2 * padding) / stride + 1;

        double[][][] output = new double[neuronCount][outputWidth][outputHeight];

        // å¯¹æ¯ä¸ªç¥ç»å…ƒ/æ»¤æ³¢å™¨è¿›è¡Œå·ç§¯æ“ä½œ
        for (int f = 0; f < neuronCount; f++) {
            for (int x = 0; x < outputWidth; x++) {
                for (int y = 0; y < outputHeight; y++) {

                    // è®¡ç®—è¾“å…¥çª—å£çš„èµ·å§‹ä½ç½®
                    int startX = x * stride - padding;
                    int startY = y * stride - padding;

                    double sum = 0.0;

                    // å¯¹æ¯ä¸ªè¾“å…¥é€šé“è¿›è¡Œå·ç§¯
                    for (int d = 0; d < inputDepth; d++) {
                        for (int i = 0; i < kernelSize; i++) {
                            for (int j = 0; j < kernelSize; j++) {
                                int inputX = startX + i;
                                int inputY = startY + j;

                                // å¤„ç†å¡«å……è¾¹ç•Œ
                                if (inputX >= 0 && inputX < inputWidth &&
                                        inputY >= 0 && inputY < inputHeight) {
                                    sum += input[d][inputX][inputY] * kernels[f][d][i][j];
                                }
                            }
                        }
                    }

                    // åº”ç”¨ReLUï¼Œä½†é™åˆ¶æœ€å¤§å€¼
                    double activation = sum + biases[f];
                    output[f][x][y] = Math.min(FunctionUtil.ReLU(activation), MAX_ACTIVATION);
                }
            }
        }

        return output;
    }

    /**
     * åå‘ä¼ æ’­
     * @param gradient ä¸Šä¸€å±‚ä¼ æ¥çš„æ¢¯åº¦ [filter][width][height]
     * @param learningRate å­¦ä¹ ç‡
     * @return ä¼ é€’ç»™ä¸‹ä¸€å±‚çš„æ¢¯åº¦ [depth][width][height]
     */
    @Override
    public double[][][] backward(double[][][] gradient, double learningRate) {
        int outputWidth = gradient[0].length;
        int outputHeight = gradient[0][0].length;

        double[][][] inputGradient = new double[inputDepth][inputWidth][inputHeight];
        double[][][][] kernelGradient = new double[neuronCount][inputDepth][kernelSize][kernelSize];
        double[] biasGradient = new double[neuronCount];

        // åˆå§‹åŒ–æ¢¯åº¦
        for (int d = 0; d < inputDepth; d++) {
            for (int x = 0; x < inputWidth; x++) {
                for (int y = 0; y < inputHeight; y++) {
                    inputGradient[d][x][y] = 0.0;
                }
            }
        }

        // è®¡ç®—æ¢¯åº¦
        for (int f = 0; f < neuronCount; f++) {
            for (int x = 0; x < outputWidth; x++) {
                for (int y = 0; y < outputHeight; y++) {

                    int startX = x * stride - padding;
                    int startY = y * stride - padding;

                    // ğŸ”¥ å…³é”®ä¿®æ”¹1ï¼šæ£€æŸ¥å½“å‰æ¢¯åº¦å€¼ï¼Œå¦‚æœå¤ªå¤§å°±è·³è¿‡
                    if (Math.abs(gradient[f][x][y]) > 10.0) {
                        // System.out.printf("è·³è¿‡è¿‡å¤§æ¢¯åº¦: %.3f%n", gradient[f][x][y]);
                        continue;
                    }

                    // è®¡ç®—å¯¹è¾“å…¥çš„æ¢¯åº¦
                    for (int d = 0; d < inputDepth; d++) {
                        for (int i = 0; i < kernelSize; i++) {
                            for (int j = 0; j < kernelSize; j++) {
                                int inputX = startX + i;
                                int inputY = startY + j;

                                if (inputX >= 0 && inputX < inputWidth &&
                                        inputY >= 0 && inputY < inputHeight) {
                                    inputGradient[d][inputX][inputY] +=
                                            kernels[f][d][i][j] * gradient[f][x][y];

                                    // è®¡ç®—å¯¹å·ç§¯æ ¸çš„æ¢¯åº¦
                                    kernelGradient[f][d][i][j] +=
                                            lastInput[d][inputX][inputY] * gradient[f][x][y];
                                }
                            }
                        }
                    }

                    // è®¡ç®—å¯¹åç½®çš„æ¢¯åº¦
                    biasGradient[f] += gradient[f][x][y];
                }
            }
        }

        // ğŸ”¥ å…³é”®ä¿®æ”¹2ï¼šæ›´ä¸¥æ ¼çš„æ¢¯åº¦è£å‰ªå’Œå‚æ•°æ›´æ–°
        double gradientNorm = 0.0;
        int paramCount = 0;

        // é¦–å…ˆè®¡ç®—æ¢¯åº¦èŒƒæ•°
        for (int f = 0; f < neuronCount; f++) {
            for (int d = 0; d < inputDepth; d++) {
                for (int i = 0; i < kernelSize; i++) {
                    for (int j = 0; j < kernelSize; j++) {
                        double grad = kernelGradient[f][d][i][j];
                        gradientNorm += grad * grad;
                        paramCount++;
                    }
                }
            }
            gradientNorm += biasGradient[f] * biasGradient[f];
            paramCount++;
        }
        gradientNorm = Math.sqrt(gradientNorm / paramCount);

        // æ¢¯åº¦è£å‰ªï¼šå¦‚æœæ¢¯åº¦èŒƒæ•°å¤ªå¤§ï¼Œè¿›è¡Œç¼©æ”¾
        double maxGradientNorm = 1.0; // æœ€å¤§å…è®¸çš„æ¢¯åº¦èŒƒæ•°
        double scale = 1.0;
        if (gradientNorm > maxGradientNorm) {
            scale = maxGradientNorm / gradientNorm;
            System.out.printf("æ¢¯åº¦è£å‰ª: èŒƒæ•° %.3f -> ç¼©æ”¾ %.3f%n", gradientNorm, scale);
        }

        // Update params with gradient clipping
        for (int f = 0; f < neuronCount; f++) {
            for (int d = 0; d < inputDepth; d++) {
                for (int i = 0; i < kernelSize; i++) {
                    for (int j = 0; j < kernelSize; j++) {
                        double grad = kernelGradient[f][d][i][j] * scale; // åº”ç”¨ç¼©æ”¾

                        // æ›´ä¸¥æ ¼çš„é€å‚æ•°æ¢¯åº¦è£å‰ª
                        if (grad > 0.1) grad = 0.1;
                        if (grad < -0.1) grad = -0.1;

                        // æ£€æŸ¥NaN
                        if (Double.isNaN(grad)) {
                            // System.out.println("å·ç§¯æ ¸æ¢¯åº¦å‡ºç° NaN");
                            grad = 0.0;
                        }

                        kernels[f][d][i][j] -= learningRate * grad;

                        // å¯é€‰ï¼šæƒé‡è£å‰ªï¼Œé˜²æ­¢æƒé‡å˜å¾—å¤ªå¤§
                        if (kernels[f][d][i][j] > 2.0) kernels[f][d][i][j] = 2.0;
                        if (kernels[f][d][i][j] < -2.0) kernels[f][d][i][j] = -2.0;
                    }
                }
            }

            // åç½®æ›´æ–°ä¹Ÿåº”ç”¨æ¢¯åº¦è£å‰ª
            double biasGrad = biasGradient[f] * scale;
            if (biasGrad > 0.1) biasGrad = 0.1;
            if (biasGrad < -0.1) biasGrad = -0.1;
            biases[f] -= learningRate * biasGrad;

            // åç½®è£å‰ª
            if (biases[f] > 2.0) biases[f] = 2.0;
            if (biases[f] < -2.0) biases[f] = -2.0;
        }

        // ğŸ”¥ å…³é”®ä¿®æ”¹3ï¼šåœ¨è¿”å›è¾“å…¥æ¢¯åº¦å‰åº”ç”¨ReLUå¯¼æ•°
        for (int d = 0; d < inputDepth; d++) {
            for (int x = 0; x < inputWidth; x++) {
                for (int y = 0; y < inputHeight; y++) {
                    // å¦‚æœå‰å‘ä¼ æ’­æ—¶è¯¥è¾“å…¥<=0ï¼Œé‚£ä¹ˆæ¢¯åº¦ä¸º0ï¼ˆReLUå¯¼æ•°ï¼‰
                    if (lastInput[d][x][y] <= 0) {
                        inputGradient[d][x][y] = 0.0;
                    }

                    // å¯¹è¾“å…¥æ¢¯åº¦ä¹Ÿè¿›è¡Œè£å‰ª
                    if (inputGradient[d][x][y] > 1.0) inputGradient[d][x][y] = 1.0;
                    if (inputGradient[d][x][y] < -1.0) inputGradient[d][x][y] = -1.0;
                }
            }
        }

        return inputGradient;
    }

}
